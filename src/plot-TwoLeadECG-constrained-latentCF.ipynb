{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f239ef",
      "metadata": {
        "id": "a0f239ef"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98202777",
      "metadata": {
        "id": "98202777"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/anger232/learning-time-series-counterfactuals.git\n",
        "# %cd learning-time-series-counterfactuals/ "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q wildboar\n",
        "# !pip install -q scikit-learn\n",
        "# !pip install -q stumpy\n",
        "# !pip install -q fastdtw\n",
        "\n",
        "# # #!pip install -q tensorflow-gpu>=1.2.0\n",
        "# # # !pip install -q -U tensor2tensor\n",
        "# # # !pip install -q tensorflow matplotlib\n",
        "# # !pip install -q matplotlib\n",
        "# # !pip install -q joblib>=0.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfAhAD1PsYuW",
        "outputId": "d148c9ad-5c98-48e2-e4cb-60a95e999496"
      },
      "id": "DfAhAD1PsYuW",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.2/136.2 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ad8718d5",
      "metadata": {
        "id": "ad8718d5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./src')\n",
        "sys.path.append('./LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a756fb",
      "metadata": {
        "id": "08a756fb"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7845e90e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7845e90e",
        "outputId": "ebdf6848-ff96-41d4-ceef-df5a0c5ad11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:numba.cuda.cudadrv.driver:Call to cuInit results in CUDA_ERROR_NO_DEVICE\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_alpha, find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef330b1e",
      "metadata": {
        "id": "ef330b1e"
      },
      "outputs": [],
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "80b4f195",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80b4f195",
        "outputId": "7181d7ca-42cc-47f5-af46-22d213ff696a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "gpu_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a87d6e5f",
      "metadata": {
        "id": "a87d6e5f"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d6ff63c0",
      "metadata": {
        "id": "d6ff63c0"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"TwoLeadECG\"\n",
        "OUTPUT_FILENAME = \"twolead-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "774a78f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "774a78f4",
        "outputId": "9bcd0ce4-7910-4d33-eda4-2b4a26c0da12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading ucr-v1.0-default.zip (231.83 MB)\n",
            "  |██████████████████████████████████████████████████| 231.83/231.83 MB\n"
          ]
        }
      ],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = 2\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "66181d53",
      "metadata": {
        "id": "66181d53"
      },
      "outputs": [],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "logger.info(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "03febb4b",
      "metadata": {
        "id": "03febb4b"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e8f551c9",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8f551c9",
        "outputId": "be5accde-889e-44be-c3f7-baa281f27f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 8s 53ms/step - loss: 0.5620 - accuracy: 0.7667 - val_loss: 0.6924 - val_accuracy: 0.4979\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.3156 - accuracy: 0.9527 - val_loss: 0.6910 - val_accuracy: 0.5150\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.2268 - accuracy: 0.9742 - val_loss: 0.6890 - val_accuracy: 0.5021\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.1736 - accuracy: 0.9860 - val_loss: 0.6878 - val_accuracy: 0.5021\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 0.1432 - accuracy: 0.9871 - val_loss: 0.6839 - val_accuracy: 0.5021\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.1240 - accuracy: 0.9849 - val_loss: 0.6791 - val_accuracy: 0.5021\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.1002 - accuracy: 0.9925 - val_loss: 0.6750 - val_accuracy: 0.5021\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0831 - accuracy: 0.9935 - val_loss: 0.6653 - val_accuracy: 0.5021\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0796 - accuracy: 0.9957 - val_loss: 0.6456 - val_accuracy: 0.5064\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0731 - accuracy: 0.9946 - val_loss: 0.6117 - val_accuracy: 0.5150\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0798 - accuracy: 0.9882 - val_loss: 0.5627 - val_accuracy: 0.5966\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0663 - accuracy: 0.9935 - val_loss: 0.5028 - val_accuracy: 0.7210\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0756 - accuracy: 0.9914 - val_loss: 0.4325 - val_accuracy: 0.8541\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0513 - accuracy: 0.9989 - val_loss: 0.3503 - val_accuracy: 0.9270\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0566 - accuracy: 0.9957 - val_loss: 0.2799 - val_accuracy: 0.9785\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0468 - accuracy: 0.9978 - val_loss: 0.2238 - val_accuracy: 0.9785\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0490 - accuracy: 0.9946 - val_loss: 0.1830 - val_accuracy: 0.9828\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.0542 - accuracy: 0.9957 - val_loss: 0.1415 - val_accuracy: 0.9914\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0483 - accuracy: 0.9968 - val_loss: 0.1172 - val_accuracy: 0.9914\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0448 - accuracy: 0.9957 - val_loss: 0.1212 - val_accuracy: 0.9828\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0403 - accuracy: 0.9989 - val_loss: 0.1102 - val_accuracy: 0.9828\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0407 - accuracy: 0.9957 - val_loss: 0.1132 - val_accuracy: 0.9742\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0391 - accuracy: 0.9978 - val_loss: 0.0710 - val_accuracy: 0.9871\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0419 - accuracy: 0.9957 - val_loss: 0.0644 - val_accuracy: 0.9914\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0363 - accuracy: 0.9957 - val_loss: 0.0534 - val_accuracy: 0.9914\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0388 - accuracy: 0.9968 - val_loss: 0.0812 - val_accuracy: 0.9871\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0318 - accuracy: 0.9989 - val_loss: 0.0498 - val_accuracy: 0.9914\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0357 - accuracy: 0.9978 - val_loss: 0.0465 - val_accuracy: 0.9914\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0350 - accuracy: 0.9978 - val_loss: 0.0435 - val_accuracy: 0.9914\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.0288 - accuracy: 0.9989 - val_loss: 0.0815 - val_accuracy: 0.9657\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 0.0332 - accuracy: 0.9946 - val_loss: 0.0542 - val_accuracy: 0.9871\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0297 - accuracy: 0.9989 - val_loss: 0.0467 - val_accuracy: 0.9871\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0304 - accuracy: 0.9989 - val_loss: 0.0498 - val_accuracy: 0.9871\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9871\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0323 - accuracy: 0.9978 - val_loss: 0.0547 - val_accuracy: 0.9871\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0286 - accuracy: 0.9968 - val_loss: 0.0671 - val_accuracy: 0.9871\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0369 - accuracy: 0.9957 - val_loss: 0.0466 - val_accuracy: 0.9914\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0244 - accuracy: 0.9989 - val_loss: 0.0421 - val_accuracy: 0.9914\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9914\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0237 - accuracy: 0.9989 - val_loss: 0.0433 - val_accuracy: 0.9914\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0299 - accuracy: 0.9978 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0316 - accuracy: 0.9968 - val_loss: 0.0508 - val_accuracy: 0.9914\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 0.0251 - accuracy: 0.9989 - val_loss: 0.0398 - val_accuracy: 0.9914\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0310 - accuracy: 0.9978 - val_loss: 0.0420 - val_accuracy: 0.9914\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0251 - accuracy: 0.9978 - val_loss: 0.0341 - val_accuracy: 0.9914\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0269 - accuracy: 0.9989 - val_loss: 0.0323 - val_accuracy: 0.9957\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9957\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9914\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0253 - accuracy: 0.9946 - val_loss: 0.0389 - val_accuracy: 0.9871\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0212 - accuracy: 0.9968 - val_loss: 0.0565 - val_accuracy: 0.9871\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9914\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9957\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0190 - accuracy: 0.9978 - val_loss: 0.0302 - val_accuracy: 0.9957\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0312 - accuracy: 0.9957 - val_loss: 0.0542 - val_accuracy: 0.9871\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0235 - accuracy: 0.9978 - val_loss: 0.0322 - val_accuracy: 0.9914\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9914\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0267 - accuracy: 0.9968 - val_loss: 0.0341 - val_accuracy: 0.9914\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0220 - accuracy: 0.9978 - val_loss: 0.0373 - val_accuracy: 0.9914\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0190 - accuracy: 0.9989 - val_loss: 0.0281 - val_accuracy: 0.9957\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0199 - accuracy: 0.9978 - val_loss: 0.0298 - val_accuracy: 0.9957\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.0202 - accuracy: 0.9978 - val_loss: 0.0261 - val_accuracy: 0.9957\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0177 - accuracy: 0.9989 - val_loss: 0.0218 - val_accuracy: 0.9957\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0291 - accuracy: 0.9946 - val_loss: 0.0252 - val_accuracy: 0.9957\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0206 - accuracy: 0.9968 - val_loss: 0.0240 - val_accuracy: 0.9957\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0171 - accuracy: 0.9989 - val_loss: 0.0284 - val_accuracy: 0.9914\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0176 - accuracy: 0.9989 - val_loss: 0.0337 - val_accuracy: 0.9914\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.0359 - val_accuracy: 0.9914\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9957\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0199 - accuracy: 0.9968 - val_loss: 0.0258 - val_accuracy: 0.9957\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0245 - accuracy: 0.9935 - val_loss: 0.0439 - val_accuracy: 0.9914\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0175 - accuracy: 0.9989 - val_loss: 0.0578 - val_accuracy: 0.9828\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9871\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9989 - val_loss: 0.0308 - val_accuracy: 0.9957\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9957\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0162 - accuracy: 0.9989 - val_loss: 0.0240 - val_accuracy: 0.9957\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0164 - accuracy: 0.9978 - val_loss: 0.0264 - val_accuracy: 0.9957\n",
            "8/8 [==============================] - 0s 6ms/step\n",
            "LSTM-FCN classifier trained, with validation accuracy 0.9957264957264957.\n",
            "Confusion matrix: \n",
            "          Pred:pos  Pred:neg\n",
            "True:pos       116         1\n",
            "True:neg         0       116.\n"
          ]
        }
      ],
      "source": [
        "n_lstmcells = 8\n",
        "\n",
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.0 LSTM-FCN classifier\n",
        "###############################################\n",
        "# ### LSTM-FCN classifier\n",
        "classifier = LSTMFCNClassifier(\n",
        "    n_timesteps_padded, n_features, n_output=2, n_LSTM_cells=n_lstmcells\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "classifier.compile(\n",
        "    optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=30, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for LSTM-FCN classifier:\")\n",
        "classifier_history = classifier.fit(\n",
        "    X_train_processed_padded,\n",
        "    y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, y_test),\n",
        "    callbacks=[early_stopping_accuracy],\n",
        ")\n",
        "\n",
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "print(f\"LSTM-FCN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "    confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "    index=[\"True:pos\", \"True:neg\"],\n",
        "    columns=[\"Pred:pos\", \"Pred:neg\"],\n",
        ")\n",
        "print(f\"Confusion matrix: \\n{confusion_matrix_df}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598e9e44",
      "metadata": {
        "id": "598e9e44"
      },
      "source": [
        "## 1dCNN search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c60c78f9",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c60c78f9",
        "outputId": "14c6765f-f85d-441b-9724-42f7b77b4f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 2s 18ms/step - loss: 0.2778 - val_loss: 0.0267\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0218 - val_loss: 0.0132\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0084\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0045\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0029\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 9.3769e-04\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 7.9424e-04 - val_loss: 6.6360e-04\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 5.7221e-04 - val_loss: 4.8137e-04\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 4.3411e-04 - val_loss: 3.8074e-04\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 3.5714e-04 - val_loss: 3.2157e-04\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 3.0788e-04 - val_loss: 2.8281e-04\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 2.7341e-04 - val_loss: 2.5476e-04\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 2.5136e-04 - val_loss: 2.4020e-04\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 2.3314e-04 - val_loss: 2.3413e-04\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 2.1465e-04 - val_loss: 2.0134e-04\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 2.0094e-04 - val_loss: 1.9299e-04\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 1.8974e-04 - val_loss: 1.7806e-04\n",
            "1dCNN autoencoder trained, with validation loss: 0.00017805688548833132.\n"
          ]
        }
      ],
      "source": [
        "###############################################\n",
        "# ## 2.1 CF search with 1dCNN autoencoder\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0.0001, patience=5, restore_best_weights=True\n",
        ")\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded,\n",
        "    X_train_processed_padded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True,\n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history[\"val_loss\"])\n",
        "print(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576d45df",
      "metadata": {
        "id": "576d45df"
      },
      "source": [
        "## CF search, original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4184c392",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4184c392",
        "outputId": "4f01b9a9-febf-484b-cca9-52f43a61c481"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3c49463cfc08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"global\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     step_weights = get_global_weights(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mX_train_processed_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_train_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/learning-time-series-counterfactuals/./src/_guided.py\u001b[0m in \u001b[0;36mget_global_weights\u001b[0;34m(input_samples, input_labels, classifier_model, random_state)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntervalImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/learning-time-series-counterfactuals/./src/_guided.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
          ]
        }
      ],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [1]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a432b662",
      "metadata": {
        "id": "a432b662"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d235be",
      "metadata": {
        "id": "82d235be"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e6e70d",
      "metadata": {
        "id": "e4e6e70d"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a1f54f",
      "metadata": {
        "id": "76a1f54f"
      },
      "outputs": [],
      "source": [
        "sample_id = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d95cf88",
      "metadata": {
        "id": "0d95cf88"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2be787d",
      "metadata": {
        "id": "b2be787d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "color = 'lightcoral' # if weight < 0 else 'green' \n",
        "plt.axvspan(0, 82, color=color, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7586c7",
      "metadata": {
        "id": "4b7586c7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8016f0",
      "metadata": {
        "id": "dd8016f0"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1fda14",
      "metadata": {
        "id": "7f1fda14"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ca1e34",
      "metadata": {
        "id": "87ca1e34"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fd9b35",
      "metadata": {
        "scrolled": false,
        "id": "81fd9b35"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "color = 'lightcoral' # if weight < 0 else 'green' \n",
        "plt.axvspan(0, 82, color=color, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9c41fe",
      "metadata": {
        "id": "8b9c41fe"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e21e9e9",
      "metadata": {
        "id": "7e21e9e9"
      },
      "source": [
        "## global, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a08016",
      "metadata": {
        "id": "a1a08016"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"global\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7453bccf",
      "metadata": {
        "id": "7453bccf"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79652cbd",
      "metadata": {
        "id": "79652cbd"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824621c9",
      "metadata": {
        "id": "824621c9"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b32072b",
      "metadata": {
        "id": "0b32072b"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60722cbb",
      "metadata": {
        "id": "60722cbb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d376469d",
      "metadata": {
        "id": "d376469d"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e29618",
      "metadata": {
        "id": "f3e29618"
      },
      "outputs": [],
      "source": [
        "from wildboar.explain import *\n",
        "\n",
        "class ModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X):\n",
        "        p = self.model.predict(X.reshape(X.shape[0], -1, 1))\n",
        "        return np.argmax(p, axis=1) # I think this would work?\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self.model.fit(X, y)\n",
        "\n",
        "clf = ModelWrapper(classifier)\n",
        "\n",
        "i = IntervalImportance(scoring=\"accuracy\", n_intervals=10, random_state=RANDOM_STATE)\n",
        "i.fit(clf, X_train_processed_padded.reshape(X_train_processed_padded.shape[0], -1), y_train_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1f6070",
      "metadata": {
        "id": "ca1f6070"
      },
      "outputs": [],
      "source": [
        "print(i.importances_.mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2de732",
      "metadata": {
        "id": "8f2de732"
      },
      "outputs": [],
      "source": [
        "seg_idx = i.intervals_\n",
        "seg_imp = i.importances_.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6d7481",
      "metadata": {
        "id": "af6d7481"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 75 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 75)\n",
        "# masking_threshold = np.percentile(i.importances_.mean, 25)\n",
        "print(masking_threshold)\n",
        "masking_idx = np.where(seg_imp >= masking_threshold)\n",
        "print(masking_idx)\n",
        "weighted_steps = np.ones(X_test_processed_padded.shape[1])\n",
        "print(weighted_steps.shape)\n",
        "\n",
        "for start_idx in masking_idx[0]:\n",
        "    weighted_steps[seg_idx[start_idx][0] : seg_idx[start_idx][1]] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5214cafb",
      "metadata": {
        "id": "5214cafb"
      },
      "outputs": [],
      "source": [
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63397e5",
      "metadata": {
        "id": "b63397e5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight)*0.5)\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7276f7af",
      "metadata": {
        "id": "7276f7af"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b3609b",
      "metadata": {
        "id": "a3b3609b"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761e7c5d",
      "metadata": {
        "id": "761e7c5d"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e17b16d",
      "metadata": {
        "id": "9e17b16d"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i][0]\n",
        "    end = seg_idx[i+1][0] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight <= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' # if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight)*0.5)\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22f6d81",
      "metadata": {
        "id": "f22f6d81"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ab66d2",
      "metadata": {
        "id": "c8ab66d2"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ebda23",
      "metadata": {
        "id": "b4ebda23"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c131798",
      "metadata": {
        "id": "0c131798"
      },
      "source": [
        "## local, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f9ddb8",
      "metadata": {
        "id": "34f9ddb8"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"local\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58076e60",
      "metadata": {
        "id": "58076e60"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2d1b88",
      "metadata": {
        "id": "3c2d1b88"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d03d8fb",
      "metadata": {
        "id": "7d03d8fb"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e12ebf",
      "metadata": {
        "id": "e4e12ebf"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fac5ab",
      "metadata": {
        "id": "38fac5ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc2cd06",
      "metadata": {
        "id": "cdc2cd06"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4625853c",
      "metadata": {
        "id": "4625853c"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "seg_imp, seg_idx = LIMESegment(\n",
        "        series,\n",
        "        classifier,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d861a320",
      "metadata": {
        "id": "d861a320"
      },
      "outputs": [],
      "source": [
        "# seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len - padding_size\n",
        "# seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d6aeee",
      "metadata": {
        "id": "f2d6aeee"
      },
      "outputs": [],
      "source": [
        "# calculate the threshold of masking, 25 percentile\n",
        "masking_threshold = np.percentile(seg_imp, 25)\n",
        "masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "masking_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62df93b",
      "metadata": {
        "id": "f62df93b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.11)#abs(weight))\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a074fc",
      "metadata": {
        "id": "d9a074fc"
      },
      "outputs": [],
      "source": [
        "from LIMESegment.Utils.explanations import LIMESegment\n",
        "\n",
        "def get_local_weights(input_sample, classifier_model, random_state=None):\n",
        "    n_timesteps, n_dims = input_sample.shape  # n_dims=1\n",
        "    seg_imp, seg_idx = LIMESegment(\n",
        "        input_sample,\n",
        "        classifier_model,\n",
        "        model_type=1,\n",
        "        cp=10,\n",
        "        window_size=10,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    # calculate the threshold of masking, 25 percentile\n",
        "    masking_threshold = np.percentile(seg_imp, 25)\n",
        "    masking_idx = np.where(seg_imp <= masking_threshold)\n",
        "\n",
        "    weighted_steps = np.ones(n_timesteps)\n",
        "    for start_idx in masking_idx[0]:\n",
        "        weighted_steps[seg_idx[start_idx] : seg_idx[start_idx + 1]] = 0\n",
        "\n",
        "    # need to reshape for multiplication in `tf.math.multiply()`\n",
        "    weighted_steps = weighted_steps.reshape(1, n_timesteps, n_dims)\n",
        "    return weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c217473",
      "metadata": {
        "id": "3c217473"
      },
      "outputs": [],
      "source": [
        "series = X_pred_neg[sample_id]\n",
        "\n",
        "step_weights = get_local_weights(\n",
        "    series, classifier, random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ea0acc",
      "metadata": {
        "id": "20ea0acc"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae653d4",
      "metadata": {
        "id": "7ae653d4"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64b22c0",
      "metadata": {
        "id": "c64b22c0"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7be967",
      "metadata": {
        "id": "8c7be967"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ed5b906",
      "metadata": {
        "id": "5ed5b906"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "# plt.legend(loc='lower left')\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    if weight >= masking_threshold: \n",
        "        continue\n",
        "    color = 'lightcoral' #if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=0.11)#abs(weight))\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634c8598",
      "metadata": {
        "id": "634c8598"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfa1633",
      "metadata": {
        "id": "dbfa1633"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85edfa96",
      "metadata": {
        "id": "85edfa96"
      },
      "source": [
        "## uniform, pred_margin_weight = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d50bdde",
      "metadata": {
        "id": "9d50bdde"
      },
      "outputs": [],
      "source": [
        "from _guided import get_global_weights\n",
        "PRED_MARGIN_W_LIST = [0.5]\n",
        "w_type = \"uniform\"\n",
        "\n",
        "if w_type == \"global\":\n",
        "    step_weights = get_global_weights(\n",
        "        X_train_processed_padded,\n",
        "        y_train_classes,\n",
        "        classifier,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "elif w_type == \"uniform\":\n",
        "    step_weights = np.ones((1, n_timesteps_padded, n_features))\n",
        "elif w_type.lower() == \"local\":\n",
        "    step_weights = \"local\"\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"A.w_type not implemented, please choose 'local', 'global' or 'uniform'.\"\n",
        "    )\n",
        "\n",
        "### Evaluation metrics\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list = [0.0001]\n",
        "    best_lr, best_cf_model, best_cf_samples, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=autoencoder,\n",
        "        lr_list=lr_list,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr}.\")\n",
        "\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred = classifier.predict(best_cf_samples)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation in 1dCNN autoencoder\n",
        "        best_cf_samples = best_cf_samples[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples, z_pred, n_timesteps\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ec3d99",
      "metadata": {
        "id": "32ec3d99"
      },
      "outputs": [],
      "source": [
        "result_writer.write_result(\n",
        "    \"1dCNN autoencoder\",\n",
        "    acc,\n",
        "    ae_val_loss,\n",
        "    best_lr,\n",
        "    evaluate_res,\n",
        "    pred_margin_weight=pred_margin_weight,\n",
        "    step_weight_type=w_type.lower(),\n",
        ")\n",
        "print(f\"Done for CF search [1dCNN autoencoder], pred_margin_weight={pred_margin_weight}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097aa798",
      "metadata": {
        "id": "097aa798"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be879d97",
      "metadata": {
        "id": "be879d97"
      },
      "source": [
        "### plot for TwoLeadECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef86620",
      "metadata": {
        "id": "9ef86620"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs[sample_id, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414ebc45",
      "metadata": {
        "id": "414ebc45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5b38f7",
      "metadata": {
        "id": "9f5b38f7"
      },
      "outputs": [],
      "source": [
        "print(z_pred[sample_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d76c19",
      "metadata": {
        "id": "a9d76c19"
      },
      "source": [
        "## NoAE search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edc9d96",
      "metadata": {
        "id": "1edc9d96"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "# ## 2.3 CF search with no autoencoder\n",
        "###############################################\n",
        "for pred_margin_weight in PRED_MARGIN_W_LIST:\n",
        "    logger.info(f\"The current prediction margin weight is {pred_margin_weight}.\")\n",
        "\n",
        "    # Get these instances of negative predictions, which is class abnormal (0); (normal is class 1)\n",
        "    X_pred_neg = X_test_processed_padded[y_pred_classes == neg_label][:10]\n",
        "\n",
        "    lr_list3 = [0.001]\n",
        "    best_lr3, best_cf_model3, best_cf_samples3, _ = find_best_lr(\n",
        "        classifier,\n",
        "        X_pred_neg,\n",
        "        autoencoder=None,\n",
        "        lr_list=lr_list3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weights=step_weights,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    print(f\"The best learning rate found is {best_lr3}.\")\n",
        "\n",
        "    # ### Evaluation metrics\n",
        "    # predicted probabilities of CFs\n",
        "    z_pred3 = classifier.predict(best_cf_samples3)[:, 1]\n",
        "    if padding_size != 0:\n",
        "        # remove extra paddings after counterfactual generation\n",
        "        best_cf_samples3 = best_cf_samples3[:, :-padding_size, :]\n",
        "        # use the unpadded X for evaluation\n",
        "        X_pred_neg_orignal = X_test_processed[y_pred_classes == neg_label][:10]\n",
        "    else:\n",
        "        X_pred_neg_orignal = X_pred_neg[:10]\n",
        "\n",
        "    evaluate_res3 = evaluate(\n",
        "        X_pred_neg_orignal, best_cf_samples3, z_pred3, n_timesteps\n",
        "    )\n",
        "\n",
        "    result_writer.write_result(\n",
        "        \"No autoencoder\",\n",
        "        acc,\n",
        "        0,\n",
        "        best_lr3,\n",
        "        evaluate_res3,\n",
        "        pred_margin_weight=pred_margin_weight,\n",
        "        step_weight_type=w_type.lower(),\n",
        "    )\n",
        "    print(f\"Done for CF search [No autoencoder], pred_margin_weight={pred_margin_weight}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee7c3a0",
      "metadata": {
        "id": "2ee7c3a0"
      },
      "outputs": [],
      "source": [
        "# Uncomment to visualize the first 5 counterfactual samples\n",
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg_orignal, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs3 = time_series_revert(best_cf_samples3, n_timesteps=n_timesteps, scaler=trained_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e56ef9a",
      "metadata": {
        "id": "3e56ef9a"
      },
      "outputs": [],
      "source": [
        "original_sample = actual_Xs[sample_id, :]\n",
        "cf_sample = actual_cfs3[sample_id, :]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(original_sample, color='b', label=\"Original ECG\")\n",
        "plt.plot(cf_sample, color='r', label=\"Counterfactual\")\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"Voltage\")\n",
        "plt.legend()\n",
        "# plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbd6994",
      "metadata": {
        "id": "fdbd6994"
      },
      "outputs": [],
      "source": [
        "step_weights.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873b2a93",
      "metadata": {
        "id": "873b2a93"
      },
      "outputs": [],
      "source": [
        "print(z_pred3[sample_id])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}