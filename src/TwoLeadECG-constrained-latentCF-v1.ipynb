{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d1f78c2",
      "metadata": {
        "id": "2d1f78c2"
      },
      "source": [
        "### Uncomment the following blocks in order to install dependencies in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/anger232/learning-time-series-counterfactuals.git\n",
        "#%cd learning-time-series-counterfactuals/ "
      ],
      "metadata": {
        "id": "jLEt3b2YtZzX"
      },
      "id": "jLEt3b2YtZzX",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4940569a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4940569a",
        "outputId": "06990b54-5e0a-48a5-e233-3ad66575ce3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.4/981.4 KB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 KB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.9/257.9 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.2/136.2 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install deps\n",
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n",
        "!pip install -q wildboar\n",
        "!pip install -q stumpy\n",
        "!pip install -q fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwnjpBvYPoIh",
        "outputId": "1c81ae19-7ea1-438b-b110-59c9c1a7d157"
      },
      "id": "MwnjpBvYPoIh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/learning-time-series-counterfactuals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e955a6e8",
      "metadata": {
        "id": "e955a6e8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./src')\n",
        "sys.path.append('./LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307ebbad",
      "metadata": {
        "id": "307ebbad"
      },
      "source": [
        "### Actual codes start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "da78e0e8",
      "metadata": {
        "id": "da78e0e8"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from wildboar.datasets import load_dataset\n",
        "from wildboar.ensemble import ShapeletForestClassifier\n",
        "from wildboar.explain.counterfactual import counterfactuals\n",
        "\n",
        "from _composite import ModifiedLatentCF\n",
        "from _vanilla import LatentCF\n",
        "from help_functions import (ResultWriter, conditional_pad, evaluate,\n",
        "                            find_best_alpha, find_best_lr, plot_graphs,\n",
        "                            reset_seeds, time_series_normalize,\n",
        "                            time_series_revert, upsample_minority,\n",
        "                            validity_score)\n",
        "from keras_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bdac5a53",
      "metadata": {
        "id": "bdac5a53"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "79751faf",
      "metadata": {
        "id": "79751faf"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logger.info(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}.\")\n",
        "RANDOM_STATE = 39\n",
        "\n",
        "DATASET_NAME = \"TwoLeadECG\"\n",
        "OUTPUT_FILENAME = \"twolead-outfile.csv\"\n",
        "result_writer = ResultWriter(file_name=OUTPUT_FILENAME, dataset_name=DATASET_NAME)\n",
        "logger.info(f\"Result writer is ready, writing to {OUTPUT_FILENAME}...\")\n",
        "result_writer.write_head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "255ed3dc",
      "metadata": {
        "id": "255ed3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a693ce8-99d0-4ef5-cd84-30b46500d345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading ucr-v1.0-default.zip (231.83 MB)\n",
            "  |██████████████████████████████████████████████████| 231.83/231.83 MB\n"
          ]
        }
      ],
      "source": [
        "# 1. Load data\n",
        "X, y = load_dataset(DATASET_NAME, repository=\"wildboar/ucr\")\n",
        "\n",
        "pos = 1\n",
        "neg = 2\n",
        "# Convert positive and negative labels to 1 and 0\n",
        "pos_label, neg_label = 1, 0\n",
        "y_copy = y.copy()\n",
        "if pos != pos_label:\n",
        "    y_copy[y==pos] = pos_label # convert/normalize positive label to 1\n",
        "if neg != neg_label:\n",
        "    y_copy[y==neg] = neg_label # convert negative label to 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_copy, test_size=0.2, random_state=RANDOM_STATE, stratify=y_copy) \n",
        "\n",
        "# Upsample the minority class\n",
        "y_train_copy = y_train.copy()\n",
        "X_train, y_train = upsample_minority(X_train, y_train, pos_label=pos_label, neg_label=neg_label)\n",
        "if y_train.shape != y_train_copy.shape:\n",
        "    logger.info(f\"Data upsampling performed, current distribution of y: \\n{pd.value_counts(y_train)}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "398b9372",
      "metadata": {
        "id": "398b9372"
      },
      "outputs": [],
      "source": [
        "# ### 1.1 Normalization - fit scaler using training data \n",
        "n_training, n_timesteps = X_train.shape\n",
        "n_features = 1\n",
        "\n",
        "X_train_processed, trained_scaler = time_series_normalize(data=X_train, n_timesteps=n_timesteps)\n",
        "X_test_processed, _ = time_series_normalize(data=X_test, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "X_train_processed_padded, padding_size = conditional_pad(X_train_processed) # add extra padding zeros if n_timesteps cannot be divided by 4, required for 1dCNN autoencoder structure\n",
        "X_test_processed_padded, _ = conditional_pad(X_test_processed) \n",
        "n_timesteps_padded = X_train_processed_padded.shape[1]\n",
        "logger.info(f\"Data pre-processed, original #timesteps={n_timesteps}, padded #timesteps={n_timesteps_padded}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2a9f72b9",
      "metadata": {
        "id": "2a9f72b9"
      },
      "outputs": [],
      "source": [
        "y_train_classes = y_train\n",
        "y_test_classes = y_test\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, len(np.unique(y_train)))\n",
        "y_test = to_categorical(y_test, len(np.unique(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bf7b163a",
      "metadata": {
        "id": "bf7b163a",
        "outputId": "e708e3df-a301-466b-8ce4-45558216e177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 2s 27ms/step - loss: 0.2778 - val_loss: 0.0267\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.0218 - val_loss: 0.0132\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0107 - val_loss: 0.0084\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0064 - val_loss: 0.0045\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0036 - val_loss: 0.0029\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0012 - val_loss: 9.3980e-04\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 7.9582e-04 - val_loss: 6.6508e-04\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 5.7274e-04 - val_loss: 4.8159e-04\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 4.3454e-04 - val_loss: 3.8096e-04\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 3.5708e-04 - val_loss: 3.2103e-04\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 3.0748e-04 - val_loss: 2.8267e-04\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 2.7305e-04 - val_loss: 2.5454e-04\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 2.5103e-04 - val_loss: 2.3928e-04\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 2.3256e-04 - val_loss: 2.3233e-04\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 2.1437e-04 - val_loss: 2.0120e-04\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 2.0072e-04 - val_loss: 1.9280e-04\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 1.9025e-04 - val_loss: 1.7867e-04\n"
          ]
        }
      ],
      "source": [
        "# ## 2. LatentCF models\n",
        "# reset seeds for numpy, tensorflow, python random package and python environment seed\n",
        "reset_seeds()\n",
        "\n",
        "###############################################\n",
        "# ## 2.1 1dCNN autoencoder + 1dCNN classifier\n",
        "###############################################\n",
        "# ### 1dCNN autoencoder\n",
        "autoencoder = Autoencoder(n_timesteps_padded, n_features)\n",
        "optimizer = keras.optimizers.legacy.Adam(lr=0.0005)\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\") \n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN autoencoder:\")\n",
        "autoencoder_history = autoencoder.fit(\n",
        "    X_train_processed_padded, \n",
        "    X_train_processed_padded, \n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    verbose=True, \n",
        "    validation_data=(X_test_processed_padded, X_test_processed_padded),\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "ae_val_loss = np.min(autoencoder_history.history['val_loss'])\n",
        "logger.info(f\"1dCNN autoencoder trained, with validation loss: {ae_val_loss}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "85274cc7",
      "metadata": {
        "id": "85274cc7"
      },
      "outputs": [],
      "source": [
        "def Classifier(n_timesteps, n_features, n_output=2, n_conv_layers=1, add_dense_layer=True):\n",
        "    # https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
        "    inputs = keras.Input(shape=(n_timesteps, n_features), dtype=\"float32\")\n",
        "    \n",
        "    if add_dense_layer:\n",
        "        x = keras.layers.Dense(128)(inputs)\n",
        "    else: \n",
        "        x = inputs\n",
        "    \n",
        "    for i in range(n_conv_layers):\n",
        "        x = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.MaxPooling1D(pool_size=2, padding=\"same\")(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(n_output, activation='softmax')(x)\n",
        "    classifier = keras.Model(inputs, outputs)\n",
        "    classifier = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "81b59010",
      "metadata": {
        "scrolled": true,
        "id": "81b59010",
        "outputId": "de3bca8b-ca2f-4f5c-ac01-e99dcb479d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 2s 30ms/step - loss: 0.6652 - accuracy: 0.6376 - val_loss: 0.6929 - val_accuracy: 0.4979\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6278 - accuracy: 0.7237 - val_loss: 0.6920 - val_accuracy: 0.4979\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5979 - accuracy: 0.8118 - val_loss: 0.6886 - val_accuracy: 0.4979\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5717 - accuracy: 0.8215 - val_loss: 0.6852 - val_accuracy: 0.4979\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5457 - accuracy: 0.8591 - val_loss: 0.6805 - val_accuracy: 0.4979\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5214 - accuracy: 0.8946 - val_loss: 0.6748 - val_accuracy: 0.4979\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4966 - accuracy: 0.9043 - val_loss: 0.6707 - val_accuracy: 0.4979\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.4759 - accuracy: 0.9140 - val_loss: 0.6582 - val_accuracy: 0.5064\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4568 - accuracy: 0.9280 - val_loss: 0.6396 - val_accuracy: 0.5923\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4375 - accuracy: 0.9215 - val_loss: 0.6294 - val_accuracy: 0.5794\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.4133 - accuracy: 0.9624 - val_loss: 0.6181 - val_accuracy: 0.5794\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.3957 - accuracy: 0.9581 - val_loss: 0.6038 - val_accuracy: 0.5837\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.3782 - accuracy: 0.9570 - val_loss: 0.5703 - val_accuracy: 0.6695\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.3635 - accuracy: 0.9677 - val_loss: 0.5497 - val_accuracy: 0.6781\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.3474 - accuracy: 0.9699 - val_loss: 0.5294 - val_accuracy: 0.6867\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 2s 64ms/step - loss: 0.3328 - accuracy: 0.9720 - val_loss: 0.5061 - val_accuracy: 0.7124\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 2s 50ms/step - loss: 0.3190 - accuracy: 0.9710 - val_loss: 0.4696 - val_accuracy: 0.7854\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.3113 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.8326\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.2958 - accuracy: 0.9806 - val_loss: 0.4150 - val_accuracy: 0.8670\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.2843 - accuracy: 0.9796 - val_loss: 0.4063 - val_accuracy: 0.8455\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.2726 - accuracy: 0.9753 - val_loss: 0.3669 - val_accuracy: 0.9013\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2647 - accuracy: 0.9828 - val_loss: 0.3595 - val_accuracy: 0.8841\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2533 - accuracy: 0.9817 - val_loss: 0.3394 - val_accuracy: 0.9056\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2444 - accuracy: 0.9903 - val_loss: 0.3085 - val_accuracy: 0.9356\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2355 - accuracy: 0.9860 - val_loss: 0.3139 - val_accuracy: 0.9270\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2278 - accuracy: 0.9860 - val_loss: 0.2894 - val_accuracy: 0.9356\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2185 - accuracy: 0.9892 - val_loss: 0.2621 - val_accuracy: 0.9657\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2115 - accuracy: 0.9914 - val_loss: 0.2638 - val_accuracy: 0.9442\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.2045 - accuracy: 0.9882 - val_loss: 0.2490 - val_accuracy: 0.9657\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1992 - accuracy: 0.9882 - val_loss: 0.2335 - val_accuracy: 0.9700\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.1923 - accuracy: 0.9892 - val_loss: 0.2350 - val_accuracy: 0.9614\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.1844 - accuracy: 0.9871 - val_loss: 0.1905 - val_accuracy: 0.9785\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.1798 - accuracy: 0.9903 - val_loss: 0.1844 - val_accuracy: 0.9871\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.1738 - accuracy: 0.9925 - val_loss: 0.1771 - val_accuracy: 0.9914\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1688 - accuracy: 0.9925 - val_loss: 0.1683 - val_accuracy: 0.9957\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1638 - accuracy: 0.9925 - val_loss: 0.1575 - val_accuracy: 0.9957\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1594 - accuracy: 0.9935 - val_loss: 0.1496 - val_accuracy: 0.9957\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1559 - accuracy: 0.9892 - val_loss: 0.1469 - val_accuracy: 0.9957\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1501 - accuracy: 0.9925 - val_loss: 0.1477 - val_accuracy: 0.9957\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1453 - accuracy: 0.9925 - val_loss: 0.1394 - val_accuracy: 0.9957\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1421 - accuracy: 0.9925 - val_loss: 0.1340 - val_accuracy: 0.9957\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1390 - accuracy: 0.9925 - val_loss: 0.1347 - val_accuracy: 0.9957\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1343 - accuracy: 0.9925 - val_loss: 0.1264 - val_accuracy: 0.9957\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1320 - accuracy: 0.9935 - val_loss: 0.1256 - val_accuracy: 0.9957\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1281 - accuracy: 0.9957 - val_loss: 0.1277 - val_accuracy: 0.9957\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1251 - accuracy: 0.9935 - val_loss: 0.1180 - val_accuracy: 0.9957\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1224 - accuracy: 0.9935 - val_loss: 0.1106 - val_accuracy: 0.9957\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1182 - accuracy: 0.9935 - val_loss: 0.1112 - val_accuracy: 0.9957\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1150 - accuracy: 0.9935 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1125 - accuracy: 0.9957 - val_loss: 0.1074 - val_accuracy: 0.9957\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1101 - accuracy: 0.9946 - val_loss: 0.1047 - val_accuracy: 0.9957\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1082 - accuracy: 0.9946 - val_loss: 0.1047 - val_accuracy: 0.9957\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1039 - accuracy: 0.9946 - val_loss: 0.1043 - val_accuracy: 0.9957\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1052 - accuracy: 0.9935 - val_loss: 0.0966 - val_accuracy: 0.9957\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0999 - accuracy: 0.9946 - val_loss: 0.0963 - val_accuracy: 0.9957\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0972 - accuracy: 0.9925 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0962 - accuracy: 0.9957 - val_loss: 0.0902 - val_accuracy: 0.9957\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0936 - accuracy: 0.9946 - val_loss: 0.0898 - val_accuracy: 0.9957\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0915 - accuracy: 0.9957 - val_loss: 0.0899 - val_accuracy: 0.9957\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0908 - accuracy: 0.9957 - val_loss: 0.0885 - val_accuracy: 0.9957\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0874 - accuracy: 0.9968 - val_loss: 0.0877 - val_accuracy: 0.9957\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0855 - accuracy: 0.9946 - val_loss: 0.0861 - val_accuracy: 0.9957\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0835 - accuracy: 0.9968 - val_loss: 0.0847 - val_accuracy: 0.9957\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0825 - accuracy: 0.9957 - val_loss: 0.0828 - val_accuracy: 0.9957\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0804 - accuracy: 0.9957 - val_loss: 0.0826 - val_accuracy: 0.9957\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0791 - accuracy: 0.9968 - val_loss: 0.0799 - val_accuracy: 0.9957\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0775 - accuracy: 0.9946 - val_loss: 0.0772 - val_accuracy: 0.9957\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0759 - accuracy: 0.9946 - val_loss: 0.0753 - val_accuracy: 0.9957\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0754 - accuracy: 0.9957 - val_loss: 0.0737 - val_accuracy: 0.9957\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0750 - accuracy: 0.9946 - val_loss: 0.0704 - val_accuracy: 0.9957\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.0712 - accuracy: 0.9968 - val_loss: 0.0724 - val_accuracy: 0.9957\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.0703 - accuracy: 0.9957 - val_loss: 0.0706 - val_accuracy: 0.9957\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.0685 - accuracy: 0.9957 - val_loss: 0.0689 - val_accuracy: 0.9957\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.0671 - accuracy: 0.9968 - val_loss: 0.0684 - val_accuracy: 0.9957\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0662 - accuracy: 0.9968 - val_loss: 0.0729 - val_accuracy: 0.9957\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0649 - accuracy: 0.9957 - val_loss: 0.0711 - val_accuracy: 0.9957\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0638 - accuracy: 0.9968 - val_loss: 0.0676 - val_accuracy: 0.9957\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0631 - accuracy: 0.9968 - val_loss: 0.0641 - val_accuracy: 0.9957\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0615 - accuracy: 0.9957 - val_loss: 0.0618 - val_accuracy: 0.9957\n"
          ]
        }
      ],
      "source": [
        "shallow_cnn = True\n",
        "# ### 1dCNN classifier\n",
        "if shallow_cnn == True:\n",
        "    logger.info(f\"Check shallow_cnn argument={shallow_cnn}, use the shallow structure.\")\n",
        "    classifier = Classifier(n_timesteps_padded, n_features, n_conv_layers=1, add_dense_layer=True) # shallow CNN for small data size\n",
        "else:\n",
        "    classifier = Classifier(n_timesteps_padded, n_features, n_conv_layers=3, add_dense_layer=False) # deeper CNN layers for data with larger size\n",
        "\n",
        "optimizer = keras.optimizers.legacy.Adam(lr=0.0001)\n",
        "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_accuracy = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "# Train the model\n",
        "reset_seeds()\n",
        "logger.info(\"Training log for 1dCNN classifier:\")\n",
        "classifier_history = classifier.fit(X_train_processed_padded, \n",
        "        y_train, \n",
        "        epochs=150,\n",
        "        batch_size=32,\n",
        "        shuffle=True, \n",
        "        verbose=True, \n",
        "        validation_data=(X_test_processed_padded, y_test),\n",
        "        callbacks=[early_stopping_accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3f69f78d",
      "metadata": {
        "id": "3f69f78d",
        "outputId": "a1835a7c-0fc1-407d-ffa4-7f7ad3c67b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Pred:pos  Pred:neg\n",
              "True:pos       117         0\n",
              "True:neg         0       116"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f14b528-fb4b-473f-8887-d4b398588a36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred:pos</th>\n",
              "      <th>Pred:neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True:pos</th>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True:neg</th>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f14b528-fb4b-473f-8887-d4b398588a36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f14b528-fb4b-473f-8887-d4b398588a36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f14b528-fb4b-473f-8887-d4b398588a36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded)\n",
        "# y_pred_classes = np.array([1 if pred > 0.5 else 0 for pred in y_pred])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "acc = balanced_accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes)\n",
        "logger.info(f\"1dCNN classifier trained, with validation accuracy {acc}.\")\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(\n",
        "        confusion_matrix(y_true=y_test_classes, y_pred=y_pred_classes, labels=[1, 0]),\n",
        "        index=['True:pos', 'True:neg'], \n",
        "        columns=['Pred:pos', 'Pred:neg']\n",
        "    )\n",
        "confusion_matrix_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c159d8",
      "metadata": {
        "id": "e2c159d8"
      },
      "source": [
        "## Get LIME local weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f7ddba00",
      "metadata": {
        "id": "f7ddba00"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('src/LIMESegment/Utils/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "523baa28",
      "metadata": {
        "id": "523baa28"
      },
      "outputs": [],
      "source": [
        "from explanations import LIMESegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f59a1c92",
      "metadata": {
        "id": "f59a1c92",
        "outputId": "dc149b9a-b18f-4030-ea51-d9c0cfb690a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "idx = 2 # explained instance\n",
        "series = X_test_processed_padded[idx]\n",
        "print(y_pred_classes[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0618da3b",
      "metadata": {
        "id": "0618da3b",
        "outputId": "1f8b23df-707e-4ca7-b14e-9dd32d904d9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.00935273,  0.38163518,  0.06110598, -0.49968559, -0.06054164,\n",
              "        -0.11175889, -0.16334246, -0.11259199, -0.00324638, -0.03935961,\n",
              "        -0.06595633]), [0, 5, 13, 19, 30, 40, 48, 53, 58, 66, 72, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "\"\"\"\n",
        "# parameters\n",
        "ts: TS array of shape T x 1 where T is length of time series\n",
        "model: Trained model on dataset array of shape n x T x 1\n",
        "model_type: String indicating if classificaton model produces binary output \"class\" or probability output \"proba\", default \"class\"\n",
        "distance: Distance metric to be used by LIMESegment default is 'dtw'\n",
        "window_size: Window size to be used by NNSegment default is T/5\n",
        "cp: Number of change points to be determinded by NNSegment default is 3\n",
        "f: Frequency parameter for RBP default is T/10\n",
        "\"\"\"\n",
        "\n",
        "explanations = LIMESegment(series, classifier, model_type='proba', cp=10, window_size=10)\n",
        "explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "188b89bb",
      "metadata": {
        "id": "188b89bb"
      },
      "outputs": [],
      "source": [
        "seg_imp, seg_idx = explanations\n",
        "total_len = len(series)\n",
        "seg_idx[-1] = total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "56c277ac",
      "metadata": {
        "id": "56c277ac",
        "outputId": "bcc30c28-765b-46d7-ecec-af2f6e063a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "series.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b22c925a",
      "metadata": {
        "id": "b22c925a",
        "outputId": "fcab4f59-325a-41cc-aec4-f3b34a9becb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0, 5: 0.009352732485197579\n",
            "5, 13: 0.3816351789165664\n",
            "13, 19: 0.06110597734122436\n",
            "19, 30: -0.49968559279451197\n",
            "30, 40: -0.06054164383326918\n",
            "40, 48: -0.11175889122945262\n",
            "48, 53: -0.16334246371338457\n",
            "53, 58: -0.112591993786375\n",
            "58, 66: -0.003246384768738203\n",
            "66, 72: -0.03935961239301466\n",
            "72, 84: -0.06595632721304637\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "plt.plot(series, color='b', label='Explained instance')\n",
        "# plt.plot(np.mean(X_test[y_test_classes == 1], axis=0), color='green', label='Mean of other class')\n",
        "plt.legend(loc='lower left')\n",
        "\n",
        "for i in range(len(seg_idx)-1):\n",
        "    weight = seg_imp[i]\n",
        "    start = seg_idx[i]\n",
        "    end = seg_idx[i+1] \n",
        "    print(f'{start}, {end}: {weight}')\n",
        "    color = 'red' if weight < 0 else 'green' \n",
        "    plt.axvspan(start, end, color=color, alpha=abs(weight))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "74485f03",
      "metadata": {
        "id": "74485f03",
        "outputId": "b8ae53fa-f630-4e35-9fa1-9c7af750b92d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "check = np.where(seg_imp >= 0.01) # seg_imp >= 0.01 or 0.1\n",
        "check[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "32813bc9",
      "metadata": {
        "id": "32813bc9",
        "outputId": "d343609e-22e7-41e1-b269-78087494f31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "weighted_steps = np.ones(total_len)\n",
        "\n",
        "for start_idx in check[0]:\n",
        "    weighted_steps[seg_idx[start_idx]: seg_idx[start_idx+1]] = 0\n",
        "weighted_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "67f56c9f",
      "metadata": {
        "id": "67f56c9f",
        "outputId": "58cacc30-19b0-437d-94e8-d7b4cb76bbee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18]),)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "np.where(weighted_steps == 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0839f7a6",
      "metadata": {
        "id": "0839f7a6"
      },
      "source": [
        "### UPDATE: modified LIME segment (TODO, intergrate the updated version in LatentCF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "efdd6b6c",
      "metadata": {
        "id": "efdd6b6c"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "import stumpy\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.utils import check_random_state\n",
        "from fastdtw import fastdtw\n",
        "import random\n",
        "from explanations import NNSegment, RBP\n",
        "\n",
        "def LIMESegment(example, model, model_type='class', distance='dtw', n=100, window_size=None, cp=None, f=None, random_state=None):\n",
        "    random_state = check_random_state(random_state)\n",
        "    if window_size is None:\n",
        "        window_size =int(example.shape[0]/5)\n",
        "    if cp is None:\n",
        "        cp = 3\n",
        "    if f is None: \n",
        "        f = int(example.shape[0]/10)\n",
        "    \n",
        "    cp_indexes = NNSegment(example.reshape(example.shape[0]), window_size, cp)\n",
        "    segment_indexes = [0] + cp_indexes + [-1]\n",
        "    generated_samples_interpretable = [random_state.binomial(1, 0.5, len(cp_indexes)+1) for _ in range(0,n)] #UPDATE HERE\n",
        "    \n",
        "    generated_samples_raw = RBP(generated_samples_interpretable, example, segment_indexes, f)\n",
        "    sample_predictions = model.predict(generated_samples_raw)\n",
        "    \n",
        "#     print(np.argmax(sample_predictions, axis=1))\n",
        "\n",
        "    if model_type == 'proba':\n",
        "        y_labels = np.argmax(sample_predictions, axis=1)\n",
        "    elif isinstance(model_type, int): #UPDATE HERE\n",
        "        y_labels = sample_predictions[:, model_type]\n",
        "    else:\n",
        "        y_labels = sample_predictions\n",
        "    \n",
        "    if distance == 'dtw':\n",
        "        distances = np.asarray([fastdtw(example, sample)[0] for sample in generated_samples_raw])\n",
        "        weights = np.exp(-(np.abs((distances - np.mean(distances))/np.std(distances)).reshape(n,)))\n",
        "    elif distance == 'euclidean':\n",
        "        distances = np.asarray([np.linalg.norm(np.ones(len(cp_indexes)+1)-x) for x in generated_samples_interpretable])\n",
        "        weights = np.exp(-(np.abs(distances**2/0.75*(len(segment_indexes)**2)).reshape(n,)))\n",
        "\n",
        "    clf = Ridge(random_state=random_state) #UPDATE HERE\n",
        "    clf.fit(generated_samples_interpretable, y_labels, weights)\n",
        "\n",
        "    return clf.coef_, segment_indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5fe9328d",
      "metadata": {
        "id": "5fe9328d",
        "outputId": "9a9177bc-f160-468d-e6cd-90d8da0bf2da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.12420748, -0.30348256,  0.00851814,  0.41249078, -0.116542  ,\n",
              "         0.10321025,  0.17609216, -0.08653669, -0.14136251, -0.01807328,\n",
              "        -0.03402139]), [0, 5, 13, 19, 30, 40, 48, 53, 58, 66, 72, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "explanations = LIMESegment(series, classifier, model_type=0, random_state=12, cp=10, window_size=10) # warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "explanations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dbb12d",
      "metadata": {
        "id": "f9dbb12d"
      },
      "source": [
        "## CF generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "496d7ac5",
      "metadata": {
        "id": "496d7ac5"
      },
      "outputs": [],
      "source": [
        "from _composite import extract_encoder_decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "99221796",
      "metadata": {
        "id": "99221796"
      },
      "outputs": [],
      "source": [
        "class ModifiedLatentCF:\n",
        "    \"\"\"Explanations by generating a counterfacutal sample in the latent space of\n",
        "    any autoencoder.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Latent-CF: A Simple Baseline for Reverse Counterfactual Explanation\n",
        "        Rachana Balasubramanian and Samuel Sharpe and Brian Barr and Jason Wittenbach and C. Bayan Brus\n",
        "        In Proceedings of the Conference on Neural Information Processing Systems, 2020\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(    \n",
        "        self, \n",
        "        probability=0.5, \n",
        "        *, \n",
        "        alpha=0.001, \n",
        "        tolerance=1e-6, \n",
        "        learning_rate=1e-3, \n",
        "        max_iter=100,\n",
        "        optimizer=None,\n",
        "        autoencoder=None,\n",
        "        only_encoder=None,\n",
        "        only_decoder=None,\n",
        "        validity_loss_weight=1.0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        probability : float, optional\n",
        "            The desired probability assigned by the model\n",
        "\n",
        "        alpha : float, optional\n",
        "            The step size\n",
        "\n",
        "        tolerance : float, optional\n",
        "            The maximum difference between the desired and assigned probability\n",
        "\n",
        "        learning_rate : float, optional\n",
        "            The learning rate of the optimizer\n",
        "\n",
        "        max_iter : int, optional\n",
        "            The maximum number of iterations\n",
        "\n",
        "        autoencoder : int, optional\n",
        "            The autoencoder for the latent representation\n",
        "\n",
        "            - if None the sample is generated in the original space\n",
        "            - if given, the autoencoder is expected to have `k` decoder layer and `k`\n",
        "              encoding layers.\n",
        "        \"\"\"\n",
        "        self.optimizer_ = tf.optimizers.legacy.Adam(learning_rate=1e-4) if optimizer is None else optimizer\n",
        "        self.mse_loss_ = keras.losses.MeanSquaredError() \n",
        "#         self.mae_loss_ = keras.losses.MeanAbsoluteError() \n",
        "        self.alpha_ = tf.constant(alpha)\n",
        "        self.probability_ = tf.constant(probability)\n",
        "        self.tolerance_ = tf.constant(tolerance)\n",
        "        self.max_iter = max_iter\n",
        "        self.autoencoder = autoencoder\n",
        "        self.only_encoder = only_encoder\n",
        "        self.only_decoder = only_decoder\n",
        "        \n",
        "        # Weights of the different loss components\n",
        "        self.validity_weight = validity_loss_weight\n",
        "        self.proximity_weight = (1 - self.validity_weight)\n",
        "\n",
        "    def fit(self, model):\n",
        "        \"\"\"Fit a new counterfactual explainer to the model\n",
        "\n",
        "        Paramaters\n",
        "        ----------\n",
        "\n",
        "        model : keras.Model\n",
        "            The model\n",
        "        \"\"\"\n",
        "        if self.autoencoder:\n",
        "            encode_input, encode_output, decode_input, decode_output = extract_encoder_decoder(self.autoencoder)\n",
        "            self.decoder_ = keras.Model(inputs=decode_input, outputs=decode_output)\n",
        "            self.encoder_ = keras.Model(inputs=encode_input, outputs=encode_output)\n",
        "        elif self.only_encoder and self.only_decoder:\n",
        "            self.encoder_ = self.only_encoder\n",
        "            self.decoder_ = self.only_decoder\n",
        "        else:\n",
        "            self.decoder_ = None\n",
        "            self.encoder_ = None\n",
        "        self.model_ = model\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Compute the differnece beteween the desired and actual probability\n",
        "\n",
        "        Paramters\n",
        "        ---------\n",
        "        x : Variable\n",
        "            Variable of the sample\n",
        "        \"\"\"\n",
        "        if self.autoencoder is None:\n",
        "            z = x\n",
        "        else:\n",
        "            z = self.decoder_(x)\n",
        "        \n",
        "        return self.model_(z)\n",
        "    \n",
        "    # TODO: add global weights in the function input?\n",
        "    def get_local_weights(self, input_sample):\n",
        "        local_explanation = LIMESegment(input_sample, self.model_, model_type='proba', cp=10, window_size=10)\n",
        "        \n",
        "        check = np.where(seg_imp <= -0.01) # TODO: decide the threshold, 0.01 or 0.1? seg_imp >= threshold or or <= -threshold???\n",
        "        weighted_steps = np.ones(total_len) # if weights are all one? => same as a normal MAE function\n",
        "        for start_idx in check[0]:\n",
        "            weighted_steps[seg_idx[start_idx]: seg_idx[start_idx+1]] = 0\n",
        "        \n",
        "        weighted_steps = weighted_steps.reshape(1, n_timesteps_padded, 1) # need to reshape for multiplication in `tf.math.multiply()`\n",
        "        return weighted_steps\n",
        "    \n",
        "\n",
        "    # The \"validity_loss\" is designed to measure the prediction probability to the desired decision boundary\n",
        "    def validity_loss(self, prediction):\n",
        "        return self.mse_loss_(self.probability_, prediction) \n",
        "    \n",
        "    # An auxiliary MAE loss function to measure the proximity with step_weights\n",
        "    def weighted_mean_absolute_error(self, original_sample, cf_sample, step_weights):\n",
        "        return tf.math.reduce_mean(\n",
        "            tf.math.multiply(tf.math.abs(original_sample - cf_sample), step_weights)\n",
        "        )\n",
        "    \n",
        "    def compute_loss(self, original_sample, z_search, step_weights): # additional input of step_weights\n",
        "        # Initialize the loss\n",
        "        loss = tf.zeros(shape=())\n",
        "        decoded = self.decoder_(z_search)\n",
        "        pred = self.model_(decoded)\n",
        "        \n",
        "        # Add validity_loss \n",
        "        valid_loss = self.validity_loss(pred)\n",
        "        loss += self.validity_weight * valid_loss\n",
        "\n",
        "        # Add proximity_loss\n",
        "        proxi_loss = self.weighted_mean_absolute_error(\n",
        "            original_sample, decoded, step_weights=tf.cast(step_weights, tf.float32)) \n",
        "        loss += self.proximity_weight * proxi_loss\n",
        "\n",
        "        return loss, valid_loss, proxi_loss\n",
        "\n",
        "    # TODO: compatible with the counterfactuals of wildboar\n",
        "    #       i.e., define the desired output target per label\n",
        "    def transform(self, x):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "        if self.only_encoder is not None: # if only encoder, then return the latent embeddings\n",
        "            _, encoded_dim1, encoded_dim2 = self.only_encoder.layers[-1].output_shape\n",
        "            result_samples = np.empty((x.shape[0], encoded_dim1, encoded_dim2)) \n",
        "        else: \n",
        "            result_samples = np.empty(x.shape)\n",
        "\n",
        "        losses = np.empty(x.shape[0])\n",
        "        for i in range(x.shape[0]):\n",
        "            if i % 50 == 0: print(f'{i} samples been transformed.')\n",
        "            \n",
        "            step_weights = self.get_local_weights(x[i])\n",
        "            x_sample, loss = self._transform_sample_z(x[np.newaxis, i], step_weights)\n",
        "\n",
        "            result_samples[i] = x_sample\n",
        "            losses[i] = loss\n",
        "\n",
        "        return result_samples, losses\n",
        "\n",
        "    def _transform_sample_z(self, x, step_weights):\n",
        "        \"\"\"Generate counterfactual explanations\n",
        "\n",
        "        x : array-like of shape [n_samples, n_timestep, n_dims]\n",
        "            The samples\n",
        "        \"\"\"\n",
        "        # TODO: check_is_fitted(self)\n",
        "        if self.only_encoder or self.autoencoder is not None:\n",
        "            z = tf.Variable(self.encoder_(x))\n",
        "        else:\n",
        "            z = tf.Variable(x, dtype=tf.float32)\n",
        "\n",
        "        it = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss, valid_loss, proxi_loss = self.compute_loss(x, z, step_weights)\n",
        "            \n",
        "        pred = self.model_(self.decoder_(z))\n",
        "        \n",
        "        # TODO: modify the loss to check both validity and proximity; how to design the condition here?\n",
        "        # while (valid_loss > self.tolerance_ or pred[:, 1] < self.probability_ or proxi_loss > 0.001)\n",
        "        while (valid_loss > self.tolerance_ or pred[:, 1] < self.probability_ ) and \\\n",
        "        (it < self.max_iter if self.max_iter else True):\n",
        "            # Get gradients of loss wrt the sample\n",
        "            grads = tape.gradient(loss, z)\n",
        "            # Update the weights of the sample\n",
        "            self.optimizer_.apply_gradients([(grads, z)])\n",
        "            \n",
        "            with tf.GradientTape() as tape:\n",
        "                loss, valid_loss, proxi_loss = self.compute_loss(x, z, step_weights)\n",
        "            it += 1\n",
        "            pred = self.model_(self.decoder_(z))\n",
        "        \n",
        "        pred = self.model_(self.decoder_(z))\n",
        "        print(f'current valid: {valid_loss}, proxi: {proxi_loss}, pred prob:{pred}, iter: {it}.')\n",
        "  \n",
        "        return z.numpy() if self.autoencoder is None else self.decoder_(z).numpy(), float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "65d35a59",
      "metadata": {
        "id": "65d35a59"
      },
      "outputs": [],
      "source": [
        "## Evaluation metrics\n",
        "# use radius to find the count of points - KDTree; a trained tree is needed for evaluation\n",
        "tree = KDTree(\n",
        "    X_train_processed[y_train_classes==pos_label].reshape(-1, n_timesteps), \n",
        "    leaf_size=40, metric='euclidean')\n",
        "max_distance = distance_matrix(\n",
        "    X_train_processed[y_train_classes==neg_label].reshape(-1, n_timesteps), \n",
        "    X_train_processed[y_train_classes==pos_label].reshape(-1, n_timesteps)).max()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e21c3e55",
      "metadata": {
        "id": "e21c3e55"
      },
      "source": [
        "### loss weight: 0.01 valid + 0.99 proxi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ec07ca78",
      "metadata": {
        "id": "ec07ca78",
        "outputId": "e2aea8f7-a487-4055-f0b0-f19b25b91cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ModifiedLatentCF at 0x7fad690b3790>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.01)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea532aa4",
      "metadata": {
        "scrolled": true,
        "id": "ea532aa4",
        "outputId": "f6be4979-a2c6-4ad7-f8da-6d51c9269ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 9ms/step\n",
            "0 samples been transformed.\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "current valid: 6.912678713888454e-07, proxi: 0.000825060997158289, pred prob:[[0.49916857 0.5008314 ]], iter: 89.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 5.311507607075328e-07, proxi: 0.0018151324475184083, pred prob:[[0.49927118 0.5007288 ]], iter: 48.\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "current valid: 3.180220460308192e-07, proxi: 0.0012456128606572747, pred prob:[[0.49943605 0.5005639 ]], iter: 69.\n",
            "4/4 [==============================] - 0s 15ms/step\n",
            "current valid: 5.742755604387639e-08, proxi: 0.0009845452150329947, pred prob:[[0.49976033 0.5002396 ]], iter: 69.\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "current valid: 1.1870074700937039e-07, proxi: 0.0010227879974991083, pred prob:[[0.49965546 0.5003445 ]], iter: 49.\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "current valid: 3.0067390980548225e-05, proxi: 0.0009671449661254883, pred prob:[[0.5054834  0.49451664]], iter: 100.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 5.682920800609281e-08, proxi: 0.003472575219348073, pred prob:[[0.49976158 0.50023836]], iter: 75.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 7.418154979177416e-09, proxi: 0.0010547254933044314, pred prob:[[0.49991387 0.5000861 ]], iter: 82.\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "current valid: 7.62154058975284e-07, proxi: 0.0007683769799768925, pred prob:[[0.499127 0.500873]], iter: 71.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 5.436252337176484e-09, proxi: 0.0010244498262181878, pred prob:[[0.49992627 0.50007373]], iter: 56.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 5.145366230863146e-07, proxi: 0.0010573877952992916, pred prob:[[0.49928266 0.5007173 ]], iter: 81.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 1.7256925843867066e-07, proxi: 0.0008698375313542783, pred prob:[[0.49958462 0.50041544]], iter: 44.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 1.1451819403873742e-07, proxi: 0.0016465237131342292, pred prob:[[0.49966162 0.50033844]], iter: 41.\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "current valid: 7.921586586689955e-08, proxi: 0.0008679734892211854, pred prob:[[0.49971855 0.50028145]], iter: 67.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 1.478934450460656e-07, proxi: 0.0010109217837452888, pred prob:[[0.49961543 0.50038457]], iter: 43.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 1.2147887140656621e-09, proxi: 0.0008517624228261411, pred prob:[[0.49996516 0.50003487]], iter: 71.\n",
            "4/4 [==============================] - 0s 15ms/step\n",
            "current valid: 2.8404093654899043e-07, proxi: 0.0006966037326492369, pred prob:[[0.49946707 0.500533  ]], iter: 56.\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "current valid: 4.5274316562426975e-07, proxi: 0.0006440608412958682, pred prob:[[0.49932715 0.5006729 ]], iter: 70.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 6.224764774742653e-07, proxi: 0.000672576657962054, pred prob:[[0.49921104 0.500789  ]], iter: 64.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 8.567087661504047e-07, proxi: 0.0013337121345102787, pred prob:[[0.49907443 0.5009256 ]], iter: 21.\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "current valid: 3.750800559032541e-09, proxi: 0.001528645516373217, pred prob:[[0.49993873 0.5000612 ]], iter: 25.\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "current valid: 2.833782275502017e-08, proxi: 0.000799132976680994, pred prob:[[0.49983165 0.5001683 ]], iter: 46.\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "current valid: 5.874093176316819e-07, proxi: 0.0006985983927734196, pred prob:[[0.4992336  0.50076646]], iter: 65.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 7.449873606901747e-08, proxi: 0.003979351371526718, pred prob:[[0.49972704 0.5002729 ]], iter: 72.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 5.869297865501721e-07, proxi: 0.0008679947932250798, pred prob:[[0.49923387 0.5007661 ]], iter: 59.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 6.387824669218389e-07, proxi: 0.0006334107602015138, pred prob:[[0.49920076 0.50079924]], iter: 86.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 3.85056296181574e-07, proxi: 0.0008733088034205139, pred prob:[[0.4993795  0.50062054]], iter: 42.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 1.0468389888274032e-07, proxi: 0.0007484846282750368, pred prob:[[0.4996765 0.5003236]], iter: 41.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 2.478227543178946e-07, proxi: 0.0010748619679361582, pred prob:[[0.49950218 0.5004978 ]], iter: 39.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 3.607636074320908e-07, proxi: 0.0010104335378855467, pred prob:[[0.49939936 0.50060064]], iter: 74.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 7.667400723221363e-07, proxi: 0.0037616845220327377, pred prob:[[0.49912438 0.50087565]], iter: 29.\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "current valid: 5.293278491080855e-07, proxi: 0.0014244494959712029, pred prob:[[0.49927244 0.50072753]], iter: 65.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 6.202246538578038e-08, proxi: 0.004290322307497263, pred prob:[[0.49975094 0.500249  ]], iter: 45.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 7.715758698623176e-08, proxi: 0.0011161338770762086, pred prob:[[0.49972227 0.5002778 ]], iter: 49.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 6.610293894482311e-07, proxi: 0.0006930693052709103, pred prob:[[0.49918693 0.500813  ]], iter: 69.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 4.11745247674844e-07, proxi: 0.0013248047325760126, pred prob:[[0.49935836 0.5006417 ]], iter: 27.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 1.4359289934873232e-07, proxi: 0.0004576267092488706, pred prob:[[0.4996211  0.50037897]], iter: 78.\n",
            "4/4 [==============================] - 0s 14ms/step\n",
            "current valid: 0.00010814351844601333, proxi: 0.0033953716047108173, pred prob:[[0.4896008 0.5103992]], iter: 100.\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "current valid: 2.6916270101651207e-08, proxi: 0.0010871951235458255, pred prob:[[0.4998359  0.50016403]], iter: 56.\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "current valid: 0.0002348993148189038, proxi: 0.0007119292276911438, pred prob:[[0.48467353 0.5153264 ]], iter: 100.\n",
            "4/4 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab892e00",
      "metadata": {
        "id": "ab892e00"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d2b276",
      "metadata": {
        "id": "50d2b276"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c585862",
      "metadata": {
        "id": "1c585862"
      },
      "source": [
        "### loss weight: 0.25 valid + 0.75 proxi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a562cb6c",
      "metadata": {
        "id": "a562cb6c"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.25)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bc5936",
      "metadata": {
        "scrolled": true,
        "id": "87bc5936"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ac4b98",
      "metadata": {
        "id": "22ac4b98"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1bdc3e",
      "metadata": {
        "id": "4b1bdc3e"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc58d89",
      "metadata": {
        "id": "5fc58d89"
      },
      "source": [
        "### loss weight: 0.5 valid + 0.5 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d43605",
      "metadata": {
        "id": "78d43605"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.5)\n",
        "\n",
        "cf_model.fit(classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212f18fe",
      "metadata": {
        "scrolled": true,
        "id": "212f18fe"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e29f240",
      "metadata": {
        "id": "7e29f240"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23cd4f6",
      "metadata": {
        "id": "b23cd4f6"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fae4b832",
      "metadata": {
        "id": "fae4b832"
      },
      "source": [
        "### loss weight: 0.75 valid + 0.25 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2d0d1a",
      "metadata": {
        "id": "fe2d0d1a"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=0.75)\n",
        "\n",
        "cf_model.fit(classifier)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918280df",
      "metadata": {
        "id": "918280df"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18a50bb",
      "metadata": {
        "id": "c18a50bb"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fc9c86",
      "metadata": {
        "id": "73fc9c86"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac37578f",
      "metadata": {
        "id": "ac37578f"
      },
      "source": [
        "### loss weight: 1 valid + 0 proxi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a555c820",
      "metadata": {
        "id": "a555c820"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "cf_model = ModifiedLatentCF(\n",
        "    probability=0.5, autoencoder=autoencoder, optimizer=tf.optimizers.legacy.Adam(learning_rate=0.0001), \n",
        "    validity_loss_weight=1.0)\n",
        "\n",
        "cf_model.fit(classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c1ce75",
      "metadata": {
        "scrolled": true,
        "id": "49c1ce75"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_processed_padded[y_pred_classes == 0]) \n",
        "# y_pred\n",
        "\n",
        "X_pred_neg = X_test_processed_padded[y_pred_classes == 0]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning) # ignore warning of matrix multiplication: https://stackoverflow.com/questions/29688168/mean-nanmean-and-warning-mean-of-empty-slice\n",
        "    cf_embeddings, losses = cf_model.transform(X_pred_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f6bf78",
      "metadata": {
        "id": "59f6bf78"
      },
      "outputs": [],
      "source": [
        "z_pred = classifier.predict(cf_embeddings)[:, 1] # predicted probabilities of CFs\n",
        "if padding_size != 0: # remove extra paddings after counterfactual generation\n",
        "    best_cf_samples = cf_embeddings[:, :-padding_size, :] \n",
        "    X_pred_neg = X_test_processed[y_pred_classes == neg_label] # use the unpadded X for evaluation\n",
        "\n",
        "evaluate_res = evaluate(X_pred_neg, best_cf_samples, z_pred, n_timesteps, tree, max_distance)\n",
        "evaluate_res #  proximity, validity, cost_mean, cost_std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c73320",
      "metadata": {
        "id": "57c73320"
      },
      "outputs": [],
      "source": [
        "# Map the results back to the original scale, for comparison\n",
        "actual_Xs = time_series_revert(X_pred_neg, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "actual_cfs = time_series_revert(best_cf_samples, n_timesteps=n_timesteps, scaler=trained_scaler)\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(1, 5): # plot first 4 samples\n",
        "    ax = plt.subplot(3, 2, i)\n",
        "    idx = i-1 # the actual index of the sample is i-1\n",
        "    ax.set_title(\"prob(z) = %.2f, prob(x)=%.2f\" % (z_pred[idx], y_pred[:, 1][idx]))\n",
        "    ax.plot(actual_Xs[idx].reshape(-1), c=\"b\")\n",
        "    ax.plot(actual_cfs[idx].reshape(-1), c=\"r\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}